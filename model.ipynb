{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train=pd.read_csv('kaggle/input/competitive-data-science-predict-future-sales/sales_train.csv')\n",
    "items=pd.read_csv('kaggle/input/competitive-data-science-predict-future-sales/items.csv')\n",
    "shops=pd.read_csv('kaggle/input/competitive-data-science-predict-future-sales/shops.csv')\n",
    "cats=pd.read_csv('kaggle/input/competitive-data-science-predict-future-sales/item_categories.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train[train.item_cnt_day < 1000]\n",
    "train = train[train.item_price < 300000]\n",
    "train = train[train.item_price > 0].reset_index(drop = True)\n",
    "\n",
    "train.loc[train.item_cnt_day < 1, \"item_cnt_day\"] = 0\n",
    "train.loc[train.shop_id == 0, 'shop_id'] = 57\n",
    "train.loc[train.shop_id == 1, 'shop_id'] = 58\n",
    "train.loc[train.shop_id == 10, 'shop_id'] = 11\n",
    "train.loc[train.shop_id == 40, 'shop_id'] = 39\n",
    "\n",
    "shops.loc[ shops.shop_name == 'Сергиев Посад ТЦ \"7Я\"',\"shop_name\" ] = 'СергиевПосад ТЦ \"7Я\"'\n",
    "shops[\"city\"] = shops.shop_name.str.split(\" \").map( lambda x: x[0] )\n",
    "shops[\"category\"] = shops.shop_name.str.split(\" \").map( lambda x: x[1] )\n",
    "shops.loc[shops.city == \"!Якутск\", \"city\"] = \"Якутск\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "category = []\n",
    "for cat in shops.category.unique():\n",
    "    if len(shops[shops.category == cat]) >= 5:\n",
    "        category.append(cat)\n",
    "shops.category = shops.category.apply( lambda x: x if (x in category) else \"other\" )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "shops[\"shop_category\"] = LabelEncoder().fit_transform( shops.category )\n",
    "shops[\"shop_city\"] = LabelEncoder().fit_transform( shops.city )\n",
    "shops = shops[[\"shop_id\", \"shop_category\", \"shop_city\"]]\n",
    "shops=shops.drop([0,1,10,40]).reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "cats[\"type_code\"] = cats.item_category_name.apply( lambda x: x.split(\" \")[0] ).astype(str)\n",
    "cats.loc[ (cats.type_code == \"Игровые\")| (cats.type_code == \"Аксессуары\"), \"category\" ] = \"Игры\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "category = []\n",
    "for cat in cats.type_code.unique():\n",
    "    if len(cats[cats.type_code == cat]) >= 5: \n",
    "        category.append( cat )\n",
    "cats.type_code = cats.type_code.apply(lambda x: x if (x in category) else \"etc\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "cats.type_code = LabelEncoder().fit_transform(cats.type_code)\n",
    "cats[\"split\"] = cats.item_category_name.apply(lambda x: x.split(\"-\"))\n",
    "cats[\"subtype\"] = cats.split.apply(lambda x: x[1].strip() if len(x) > 1 else x[0].strip())\n",
    "cats[\"subtype_code\"] = LabelEncoder().fit_transform( cats[\"subtype\"] )\n",
    "cats = cats[[\"item_category_id\", \"subtype_code\", \"type_code\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def name_correction(x):\n",
    "    x = x.lower() # all letters lower case\n",
    "    x = x.partition('[')[0] # partition by square brackets\n",
    "    x = x.partition('(')[0] # partition by curly brackets\n",
    "    x = re.sub('[^A-Za-z0-9А-Яа-я]+', ' ', x) # remove special characters\n",
    "    x = x.replace('  ', ' ') # replace double spaces with single spaces\n",
    "    x = x.strip() # remove leading and trailing white space\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Decrypt\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\ipykernel_launcher.py:2: FutureWarning: Columnar iteration over characters will be deprecated in future releases.\n",
      "  \n",
      "C:\\Users\\Decrypt\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\ipykernel_launcher.py:3: FutureWarning: Columnar iteration over characters will be deprecated in future releases.\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "# split item names by first bracket\n",
    "items[\"name1\"], items[\"name2\"] = items.item_name.str.split(\"[\", 1).str\n",
    "items[\"name1\"], items[\"name3\"] = items.item_name.str.split(\"(\", 1).str\n",
    "\n",
    "# replace special characters and turn to lower case\n",
    "items[\"name2\"] = items.name2.str.replace('[^A-Za-z0-9А-Яа-я]+', \" \").str.lower()\n",
    "items[\"name3\"] = items.name3.str.replace('[^A-Za-z0-9А-Яа-я]+', \" \").str.lower()\n",
    "\n",
    "# fill nulls with '0'\n",
    "items = items.fillna('0')\n",
    "\n",
    "items[\"item_name\"] = items[\"item_name\"].apply(lambda x: name_correction(x))\n",
    "\n",
    "# return all characters except the last if name 2 is not \"0\" - the closing bracket\n",
    "items.name2 = items.name2.apply( lambda x: x[:-1] if x !=\"0\" else \"0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "items[\"type\"] = items.name2.apply(lambda x: x[0:8] if x.split(\" \")[0] == \"xbox\" else x.split(\" \")[0] )\n",
    "items.loc[(items.type == \"x360\") | (items.type == \"xbox360\") | (items.type == \"xbox 360\") ,\"type\"] = \"xbox 360\"\n",
    "items.loc[ items.type == \"\", \"type\"] = \"mac\"\n",
    "items.type = items.type.apply( lambda x: x.replace(\" \", \"\") )\n",
    "items.loc[ (items.type == 'pc' )| (items.type == 'pс') | (items.type == \"pc\"), \"type\" ] = \"pc\"\n",
    "items.loc[ items.type == 'рs3' , \"type\"] = \"ps3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_sum = items.groupby([\"type\"]).agg({\"item_id\": \"count\"})\n",
    "group_sum = group_sum.reset_index()\n",
    "drop_cols = []\n",
    "for cat in group_sum.type.unique():\n",
    "    if group_sum.loc[(group_sum.type == cat), \"item_id\"].values[0] <40:\n",
    "        drop_cols.append(cat)\n",
    "items.name2 = items.name2.apply( lambda x: \"other\" if (x in drop_cols) else x )\n",
    "items = items.drop([\"type\"], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "items.name2 = LabelEncoder().fit_transform(items.name2)\n",
    "items.name3 = LabelEncoder().fit_transform(items.name3)\n",
    "\n",
    "items.drop([\"item_name\", \"name1\"],axis = 1, inplace= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "price=train[['item_id','item_price']]\n",
    "price=price.groupby(['item_id']).mean()\n",
    "price=price.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train=train.drop('date',axis=1)\n",
    "train=train.groupby(['date_block_num', 'shop_id', 'item_id']).sum()\n",
    "train.drop('item_price',axis=1,inplace=True)\n",
    "train=train.reset_index()\n",
    "train=train.rename(columns = {'item_cnt_day' : 'item_cnt_month'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import product\n",
    "matrix = []\n",
    "cols  = [\"date_block_num\", \"shop_id\", \"item_id\"]\n",
    "for i in range(34):\n",
    "    matrix.append( np.array(list( product( [i], shops.shop_id.unique(), price.item_id.unique() ) ), dtype = np.int16) )\n",
    "\n",
    "matrix = pd.DataFrame( np.vstack(matrix), columns = cols )\n",
    "matrix[\"date_block_num\"] = matrix[\"date_block_num\"].astype(np.int8)\n",
    "matrix[\"shop_id\"] = matrix[\"shop_id\"].astype(np.int8)\n",
    "matrix[\"item_id\"] = matrix[\"item_id\"].astype(np.int16)\n",
    "matrix.sort_values( cols, inplace = True )\n",
    "matrix=matrix.reset_index(drop=True)\n",
    "matrix=pd.merge(matrix,train,on=[\"date_block_num\", \"shop_id\", \"item_id\"],how='left')\n",
    "matrix=matrix.fillna(0)\n",
    "\n",
    "matrix=pd.merge(matrix,price,on=['item_id'],how='inner')\n",
    "matrix=pd.merge(matrix,items,on=['item_id'],how='inner')\n",
    "matrix=pd.merge(matrix,cats,on=['item_category_id'],how='inner')\n",
    "matrix=pd.merge(matrix,shops,on=['shop_id'],how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix[\"month\"] = matrix[\"date_block_num\"] % 12\n",
    "days = pd.Series([31,28,31,30,31,30,31,31,30,31,30,31])\n",
    "matrix[\"days\"] = matrix[\"month\"].map(days).astype(np.int8)\n",
    "matrix[\"year\"] = 2013+(matrix[\"date_block_num\"]/12).astype(np.int16)\n",
    "matrix['month']=matrix['month']+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix=matrix[['date_block_num', 'shop_id', 'item_id', 'shop_category', 'shop_city',\n",
    "       'item_category_id', 'name2', 'name3', 'subtype_code', 'type_code', 'days', 'month', 'year',\n",
    "       'item_price', 'item_cnt_month']]\n",
    "\n",
    "shopitemdetails=matrix.drop(['date_block_num','item_cnt_month','days','month','year'],axis=1)\n",
    "shopitemdetails=shopitemdetails.groupby(['shop_id', 'item_id', 'shop_category', 'shop_city',\n",
    "       'item_category_id', 'name2', 'name3', 'subtype_code', 'type_code']).mean()\n",
    "shopitemdetails=shopitemdetails.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "shopitemdetails.to_csv('shopitem.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = matrix[matrix.date_block_num < 33].drop(['item_cnt_month'], axis=1)\n",
    "Y_train = matrix[matrix.date_block_num < 33]['item_cnt_month']\n",
    "X_valid = matrix[matrix.date_block_num == 33].drop(['item_cnt_month'], axis=1)\n",
    "Y_valid = matrix[matrix.date_block_num == 33]['item_cnt_month']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train = Y_train.clip(0, 20)\n",
    "Y_valid = Y_valid.clip(0, 20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBRegressor\n",
    "from matplotlib.pylab import rcParams\n",
    "rcParams['figure.figsize'] = 12, 4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40297488, 14)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 2.10 GiB for an array with shape (564164832,) and data type float32",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-24-697c3f991a7a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0meval_set\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mX_valid\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY_valid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m     early_stopping_rounds = 20)\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\xgboost\\sklearn.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, base_margin, eval_set, eval_metric, early_stopping_rounds, verbose, xgb_model, sample_weight_eval_set, callbacks)\u001b[0m\n\u001b[0;32m    505\u001b[0m                                 \u001b[0mbase_margin\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbase_margin\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    506\u001b[0m                                 \u001b[0mmissing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmissing\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 507\u001b[1;33m                                 nthread=self.n_jobs)\n\u001b[0m\u001b[0;32m    508\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    509\u001b[0m         \u001b[0mevals_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\xgboost\\core.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, data, label, weight, base_margin, missing, silent, feature_names, feature_types, nthread)\u001b[0m\n\u001b[0;32m    436\u001b[0m             \u001b[0mthreads\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnthread\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    437\u001b[0m             \u001b[0mfeature_names\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfeature_names\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 438\u001b[1;33m             feature_types=feature_types)\n\u001b[0m\u001b[0;32m    439\u001b[0m         \u001b[1;32massert\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    440\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\xgboost\\data.py\u001b[0m in \u001b[0;36mdispatch_data_backend\u001b[1;34m(data, missing, threads, feature_names, feature_types)\u001b[0m\n\u001b[0;32m    502\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0m_is_pandas_df\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    503\u001b[0m         return _from_pandas_df(data, missing, threads,\n\u001b[1;32m--> 504\u001b[1;33m                                feature_names, feature_types)\n\u001b[0m\u001b[0;32m    505\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0m_is_pandas_series\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    506\u001b[0m         return _from_pandas_series(data, missing, threads, feature_names,\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\xgboost\\data.py\u001b[0m in \u001b[0;36m_from_pandas_df\u001b[1;34m(data, missing, nthread, feature_names, feature_types)\u001b[0m\n\u001b[0;32m    219\u001b[0m         data, feature_names, feature_types)\n\u001b[0;32m    220\u001b[0m     return _from_numpy_array(data, missing, nthread, feature_names,\n\u001b[1;32m--> 221\u001b[1;33m                              feature_types)\n\u001b[0m\u001b[0;32m    222\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    223\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\xgboost\\data.py\u001b[0m in \u001b[0;36m_from_numpy_array\u001b[1;34m(data, missing, nthread, feature_names, feature_types)\u001b[0m\n\u001b[0;32m    133\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    134\u001b[0m     \"\"\"\n\u001b[1;32m--> 135\u001b[1;33m     \u001b[0mflatten\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_transform_np_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    136\u001b[0m     \u001b[0mhandle\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mctypes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mc_void_p\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    137\u001b[0m     _check_call(_LIB.XGDMatrixCreateFromMat_omp(\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\xgboost\\data.py\u001b[0m in \u001b[0;36m_transform_np_array\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m    114\u001b[0m     \u001b[1;31m# explicitly tell np.array to try and avoid copying)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    115\u001b[0m     flatten = np.array(data.reshape(data.size), copy=False,\n\u001b[1;32m--> 116\u001b[1;33m                        dtype=np.float32)\n\u001b[0m\u001b[0;32m    117\u001b[0m     \u001b[0mflatten\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_maybe_np_slice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mflatten\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    118\u001b[0m     \u001b[0m_check_complex\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 2.10 GiB for an array with shape (564164832,) and data type float32"
     ]
    }
   ],
   "source": [
    "\n",
    "model.fit(\n",
    "    X_train, \n",
    "    Y_train, \n",
    "    eval_metric=\"rmse\", \n",
    "    eval_set=[(X_train, Y_train), (X_valid, Y_valid)], \n",
    "    verbose=True, \n",
    "    early_stopping_rounds = 20)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(model,open('model.pkl','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=pickle.load(open('model.pkl','rb'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.6 64-bit",
   "language": "python",
   "name": "python37664bit28ccce69e95e4e4697ca79621f8441a0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
