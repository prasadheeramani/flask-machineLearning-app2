{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "The Future Sales competition is the final assesment in the 'How to win a Data Science' course in the Advanced Machine Learning specialisation from HSE University, Moscow. The aim is to predict the monthly sales of items in specific shops, given historical data. The sale counts are clipped between 0 and 20."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set(style=\"darkgrid\")\n",
    "\n",
    "\n",
    "import os\n",
    "# for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "#     for filename in filenames:\n",
    "#         print(os.path.join(dirname, filename))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "items=pd.read_csv(\"/kaggle/input/competitive-data-science-predict-future-sales/items.csv\")\n",
    "shops=pd.read_csv(\"/kaggle/input/competitive-data-science-predict-future-sales/shops.csv\")\n",
    "cats=pd.read_csv(\"/kaggle/input/competitive-data-science-predict-future-sales/item_categories.csv\")\n",
    "train=pd.read_csv(\"/kaggle/input/competitive-data-science-predict-future-sales/sales_train.csv\")\n",
    "test=pd.read_csv(\"/kaggle/input/competitive-data-science-predict-future-sales/test.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Data Cleaning\n",
    "\n",
    "We'll remove outliers, clean up some of the raw data and add some new variables to it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Remove outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,4))\n",
    "plt.xlim(-100, 3000)\n",
    "flierprops = dict(marker='o', markerfacecolor='purple', markersize=6,\n",
    "                  linestyle='none', markeredgecolor='black')\n",
    "sns.boxplot(x=train.item_cnt_day, flierprops=flierprops)\n",
    "\n",
    "plt.figure(figsize=(10,4))\n",
    "plt.xlim(train.item_price.min(), train.item_price.max()*1.1)\n",
    "sns.boxplot(x=train.item_price, flierprops=flierprops)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll remove the obvious outliers in the dataset - the items that sold more than 1000 in one day and the item with price greater than 300,000."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train[(train.item_price < 300000 )& (train.item_cnt_day < 1000)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove any rows from train where item price is negative - these could be refunds. Also make zero and item_cnt_day values less than one, to remove negative values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train[train.item_price > 0].reset_index(drop = True)\n",
    "train.loc[train.item_cnt_day < 1, \"item_cnt_day\"] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning Shop Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Several of the shops look like duplicates of each other. This could be down to shops re-opening or possibly moving store location on the same street or shopping centre."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Якутск Орджоникидзе, 56\n",
    "train.loc[train.shop_id == 0, 'shop_id'] = 57\n",
    "test.loc[test.shop_id == 0, 'shop_id'] = 57\n",
    "# Якутск ТЦ \"Центральный\"\n",
    "train.loc[train.shop_id == 1, 'shop_id'] = 58\n",
    "test.loc[test.shop_id == 1, 'shop_id'] = 58\n",
    "# Жуковский ул. Чкалова 39м²\n",
    "train.loc[train.shop_id == 10, 'shop_id'] = 11\n",
    "test.loc[test.shop_id == 10, 'shop_id'] = 11"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clean up some shop names and add 'city' and 'category' to shops df."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shops.loc[ shops.shop_name == 'Сергиев Посад ТЦ \"7Я\"',\"shop_name\" ] = 'СергиевПосад ТЦ \"7Я\"'\n",
    "shops[\"city\"] = shops.shop_name.str.split(\" \").map( lambda x: x[0] )\n",
    "shops[\"category\"] = shops.shop_name.str.split(\" \").map( lambda x: x[1] )\n",
    "shops.loc[shops.city == \"!Якутск\", \"city\"] = \"Якутск\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Only keep shop category if there are 5 or more shops of that category, the rest are grouped as \"other\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "category = []\n",
    "for cat in shops.category.unique():\n",
    "    if len(shops[shops.category == cat]) >= 5:\n",
    "        category.append(cat)\n",
    "shops.category = shops.category.apply( lambda x: x if (x in category) else \"other\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "shops[\"shop_category\"] = LabelEncoder().fit_transform( shops.category )\n",
    "shops[\"shop_city\"] = LabelEncoder().fit_transform( shops.city )\n",
    "shops = shops[[\"shop_id\", \"shop_category\", \"shop_city\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning Item Category Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cats[\"type_code\"] = cats.item_category_name.apply( lambda x: x.split(\" \")[0] ).astype(str)\n",
    "cats.loc[ (cats.type_code == \"Игровые\")| (cats.type_code == \"Аксессуары\"), \"category\" ] = \"Игры\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "category = []\n",
    "for cat in cats.type_code.unique():\n",
    "    if len(cats[cats.type_code == cat]) >= 5: \n",
    "        category.append( cat )\n",
    "cats.type_code = cats.type_code.apply(lambda x: x if (x in category) else \"etc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cats.type_code = LabelEncoder().fit_transform(cats.type_code)\n",
    "cats[\"split\"] = cats.item_category_name.apply(lambda x: x.split(\"-\"))\n",
    "cats[\"subtype\"] = cats.split.apply(lambda x: x[1].strip() if len(x) > 1 else x[0].strip())\n",
    "cats[\"subtype_code\"] = LabelEncoder().fit_transform( cats[\"subtype\"] )\n",
    "cats = cats[[\"item_category_id\", \"subtype_code\", \"type_code\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning Item Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def name_correction(x):\n",
    "    x = x.lower() # all letters lower case\n",
    "    x = x.partition('[')[0] # partition by square brackets\n",
    "    x = x.partition('(')[0] # partition by curly brackets\n",
    "    x = re.sub('[^A-Za-z0-9А-Яа-я]+', ' ', x) # remove special characters\n",
    "    x = x.replace('  ', ' ') # replace double spaces with single spaces\n",
    "    x = x.strip() # remove leading and trailing white space\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clean item names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split item names by first bracket\n",
    "items[\"name1\"], items[\"name2\"] = items.item_name.str.split(\"[\", 1).str\n",
    "items[\"name1\"], items[\"name3\"] = items.item_name.str.split(\"(\", 1).str\n",
    "\n",
    "# replace special characters and turn to lower case\n",
    "items[\"name2\"] = items.name2.str.replace('[^A-Za-z0-9А-Яа-я]+', \" \").str.lower()\n",
    "items[\"name3\"] = items.name3.str.replace('[^A-Za-z0-9А-Яа-я]+', \" \").str.lower()\n",
    "\n",
    "# fill nulls with '0'\n",
    "items = items.fillna('0')\n",
    "\n",
    "items[\"item_name\"] = items[\"item_name\"].apply(lambda x: name_correction(x))\n",
    "\n",
    "# return all characters except the last if name 2 is not \"0\" - the closing bracket\n",
    "items.name2 = items.name2.apply( lambda x: x[:-1] if x !=\"0\" else \"0\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clean item type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "items[\"type\"] = items.name2.apply(lambda x: x[0:8] if x.split(\" \")[0] == \"xbox\" else x.split(\" \")[0] )\n",
    "items.loc[(items.type == \"x360\") | (items.type == \"xbox360\") | (items.type == \"xbox 360\") ,\"type\"] = \"xbox 360\"\n",
    "items.loc[ items.type == \"\", \"type\"] = \"mac\"\n",
    "items.type = items.type.apply( lambda x: x.replace(\" \", \"\") )\n",
    "items.loc[ (items.type == 'pc' )| (items.type == 'pс') | (items.type == \"pc\"), \"type\" ] = \"pc\"\n",
    "items.loc[ items.type == 'рs3' , \"type\"] = \"ps3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_sum = items.groupby([\"type\"]).agg({\"item_id\": \"count\"})\n",
    "group_sum = group_sum.reset_index()\n",
    "drop_cols = []\n",
    "for cat in group_sum.type.unique():\n",
    "    if group_sum.loc[(group_sum.type == cat), \"item_id\"].values[0] <40:\n",
    "        drop_cols.append(cat)\n",
    "items.name2 = items.name2.apply( lambda x: \"other\" if (x in drop_cols) else x )\n",
    "items = items.drop([\"type\"], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "items.name2 = LabelEncoder().fit_transform(items.name2)\n",
    "items.name3 = LabelEncoder().fit_transform(items.name3)\n",
    "\n",
    "items.drop([\"item_name\", \"name1\"],axis = 1, inplace= True)\n",
    "items.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing\n",
    "\n",
    "Create a matrix df with every combination of month, shop and item in order of increasing month. Item_cnt_day is summed into an item_cnt_month."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import product\n",
    "import time\n",
    "ts = time.time()\n",
    "matrix = []\n",
    "cols  = [\"date_block_num\", \"shop_id\", \"item_id\"]\n",
    "for i in range(34):\n",
    "    sales = train[train.date_block_num == i]\n",
    "    matrix.append( np.array(list( product( [i], sales.shop_id.unique(), sales.item_id.unique() ) ), dtype = np.int16) )\n",
    "\n",
    "matrix = pd.DataFrame( np.vstack(matrix), columns = cols )\n",
    "matrix[\"date_block_num\"] = matrix[\"date_block_num\"].astype(np.int8)\n",
    "matrix[\"shop_id\"] = matrix[\"shop_id\"].astype(np.int8)\n",
    "matrix[\"item_id\"] = matrix[\"item_id\"].astype(np.int16)\n",
    "matrix.sort_values( cols, inplace = True )\n",
    "time.time()- ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add revenue to train df\n",
    "train[\"revenue\"] = train[\"item_cnt_day\"] * train[\"item_price\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts = time.time()\n",
    "group = train.groupby( [\"date_block_num\", \"shop_id\", \"item_id\"] ).agg( {\"item_cnt_day\": [\"sum\"]} )\n",
    "group.columns = [\"item_cnt_month\"]\n",
    "group.reset_index( inplace = True)\n",
    "matrix = pd.merge( matrix, group, on = cols, how = \"left\" )\n",
    "matrix[\"item_cnt_month\"] = matrix[\"item_cnt_month\"].fillna(0).astype(np.float16)\n",
    "time.time() - ts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a test set for month 34."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test[\"date_block_num\"] = 34\n",
    "test[\"date_block_num\"] = test[\"date_block_num\"].astype(np.int8)\n",
    "test[\"shop_id\"] = test.shop_id.astype(np.int8)\n",
    "test[\"item_id\"] = test.item_id.astype(np.int16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Concatenate train and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts = time.time()\n",
    "\n",
    "matrix = pd.concat([matrix, test.drop([\"ID\"],axis = 1)], ignore_index=True, sort=False, keys=cols)\n",
    "matrix.fillna( 0, inplace = True )\n",
    "time.time() - ts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add shop, items and categories data onto matrix df."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "ts = time.time()\n",
    "matrix = pd.merge( matrix, shops, on = [\"shop_id\"], how = \"left\" )\n",
    "matrix = pd.merge(matrix, items, on = [\"item_id\"], how = \"left\")\n",
    "matrix = pd.merge( matrix, cats, on = [\"item_category_id\"], how = \"left\" )\n",
    "matrix[\"shop_city\"] = matrix[\"shop_city\"].astype(np.int8)\n",
    "matrix[\"shop_category\"] = matrix[\"shop_category\"].astype(np.int8)\n",
    "matrix[\"item_category_id\"] = matrix[\"item_category_id\"].astype(np.int8)\n",
    "matrix[\"subtype_code\"] = matrix[\"subtype_code\"].astype(np.int8)\n",
    "matrix[\"name2\"] = matrix[\"name2\"].astype(np.int8)\n",
    "matrix[\"name3\"] = matrix[\"name3\"].astype(np.int16)\n",
    "matrix[\"type_code\"] = matrix[\"type_code\"].astype(np.int8)\n",
    "time.time() - ts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature Engineering\n",
    "\n",
    "* Add lag features to matrix df."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a lag feature function\n",
    "def lag_feature( df,lags, cols ):\n",
    "    for col in cols:\n",
    "        print(col)\n",
    "        tmp = df[[\"date_block_num\", \"shop_id\",\"item_id\",col ]]\n",
    "        for i in lags:\n",
    "            shifted = tmp.copy()\n",
    "            shifted.columns = [\"date_block_num\", \"shop_id\", \"item_id\", col + \"_lag_\"+str(i)]\n",
    "            shifted.date_block_num = shifted.date_block_num + i\n",
    "            df = pd.merge(df, shifted, on=['date_block_num','shop_id','item_id'], how='left')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add item_cnt_month lag features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts = time.time()\n",
    "matrix = lag_feature( matrix, [1,2,3], [\"item_cnt_month\"] )\n",
    "time.time() - ts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add the previous month's average item_cnt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts = time.time()\n",
    "group = matrix.groupby( [\"date_block_num\"] ).agg({\"item_cnt_month\" : [\"mean\"]})\n",
    "group.columns = [\"date_avg_item_cnt\"]\n",
    "group.reset_index(inplace = True)\n",
    "\n",
    "matrix = pd.merge(matrix, group, on = [\"date_block_num\"], how = \"left\")\n",
    "matrix.date_avg_item_cnt = matrix[\"date_avg_item_cnt\"].astype(np.float16)\n",
    "matrix = lag_feature( matrix, [1], [\"date_avg_item_cnt\"] )\n",
    "matrix.drop( [\"date_avg_item_cnt\"], axis = 1, inplace = True )\n",
    "time.time() - ts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add lag values of item_cnt_month for month / item_id."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts = time.time()\n",
    "group = matrix.groupby(['date_block_num', 'item_id']).agg({'item_cnt_month': ['mean']})\n",
    "group.columns = [ 'date_item_avg_item_cnt' ]\n",
    "group.reset_index(inplace=True)\n",
    "\n",
    "matrix = pd.merge(matrix, group, on=['date_block_num','item_id'], how='left')\n",
    "matrix.date_item_avg_item_cnt = matrix['date_item_avg_item_cnt'].astype(np.float16)\n",
    "matrix = lag_feature(matrix, [1,2,3], ['date_item_avg_item_cnt'])\n",
    "matrix.drop(['date_item_avg_item_cnt'], axis=1, inplace=True)\n",
    "time.time() - ts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add lag values for item_cnt_month for every month / shop combination."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts = time.time()\n",
    "group = matrix.groupby( [\"date_block_num\",\"shop_id\"] ).agg({\"item_cnt_month\" : [\"mean\"]})\n",
    "group.columns = [\"date_shop_avg_item_cnt\"]\n",
    "group.reset_index(inplace = True)\n",
    "\n",
    "matrix = pd.merge(matrix, group, on = [\"date_block_num\",\"shop_id\"], how = \"left\")\n",
    "matrix.date_avg_item_cnt = matrix[\"date_shop_avg_item_cnt\"].astype(np.float16)\n",
    "matrix = lag_feature( matrix, [1,2,3], [\"date_shop_avg_item_cnt\"] )\n",
    "matrix.drop( [\"date_shop_avg_item_cnt\"], axis = 1, inplace = True )\n",
    "time.time() - ts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add lag values for item_cnt_month for month/shop/item."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts = time.time()\n",
    "group = matrix.groupby( [\"date_block_num\",\"shop_id\",\"item_id\"] ).agg({\"item_cnt_month\" : [\"mean\"]})\n",
    "group.columns = [\"date_shop_item_avg_item_cnt\"]\n",
    "group.reset_index(inplace = True)\n",
    "\n",
    "matrix = pd.merge(matrix, group, on = [\"date_block_num\",\"shop_id\",\"item_id\"], how = \"left\")\n",
    "matrix.date_avg_item_cnt = matrix[\"date_shop_item_avg_item_cnt\"].astype(np.float16)\n",
    "matrix = lag_feature( matrix, [1,2,3], [\"date_shop_item_avg_item_cnt\"] )\n",
    "matrix.drop( [\"date_shop_item_avg_item_cnt\"], axis = 1, inplace = True )\n",
    "time.time() - ts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add lag values for item_cnt_month for month/shop/item subtype."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts = time.time()\n",
    "group = matrix.groupby(['date_block_num', 'shop_id', 'subtype_code']).agg({'item_cnt_month': ['mean']})\n",
    "group.columns = ['date_shop_subtype_avg_item_cnt']\n",
    "group.reset_index(inplace=True)\n",
    "\n",
    "matrix = pd.merge(matrix, group, on=['date_block_num', 'shop_id', 'subtype_code'], how='left')\n",
    "matrix.date_shop_subtype_avg_item_cnt = matrix['date_shop_subtype_avg_item_cnt'].astype(np.float16)\n",
    "matrix = lag_feature(matrix, [1], ['date_shop_subtype_avg_item_cnt'])\n",
    "matrix.drop(['date_shop_subtype_avg_item_cnt'], axis=1, inplace=True)\n",
    "time.time() - ts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add lag values for item_cnt_month for month/city."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts = time.time()\n",
    "group = matrix.groupby(['date_block_num', 'shop_city']).agg({'item_cnt_month': ['mean']})\n",
    "group.columns = ['date_city_avg_item_cnt']\n",
    "group.reset_index(inplace=True)\n",
    "\n",
    "matrix = pd.merge(matrix, group, on=['date_block_num', \"shop_city\"], how='left')\n",
    "matrix.date_city_avg_item_cnt = matrix['date_city_avg_item_cnt'].astype(np.float16)\n",
    "matrix = lag_feature(matrix, [1], ['date_city_avg_item_cnt'])\n",
    "matrix.drop(['date_city_avg_item_cnt'], axis=1, inplace=True)\n",
    "time.time() - ts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add lag values for item_cnt_month for month/city/item."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts = time.time()\n",
    "group = matrix.groupby(['date_block_num', 'item_id', 'shop_city']).agg({'item_cnt_month': ['mean']})\n",
    "group.columns = [ 'date_item_city_avg_item_cnt' ]\n",
    "group.reset_index(inplace=True)\n",
    "\n",
    "matrix = pd.merge(matrix, group, on=['date_block_num', 'item_id', 'shop_city'], how='left')\n",
    "matrix.date_item_city_avg_item_cnt = matrix['date_item_city_avg_item_cnt'].astype(np.float16)\n",
    "matrix = lag_feature(matrix, [1], ['date_item_city_avg_item_cnt'])\n",
    "matrix.drop(['date_item_city_avg_item_cnt'], axis=1, inplace=True)\n",
    "time.time() - ts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Add average item price on to matix df. \n",
    "* Add lag values of item price per month.\n",
    "* Add delta price values - how current month average pirce relates to global average."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts = time.time()\n",
    "group = train.groupby( [\"item_id\"] ).agg({\"item_price\": [\"mean\"]})\n",
    "group.columns = [\"item_avg_item_price\"]\n",
    "group.reset_index(inplace = True)\n",
    "\n",
    "matrix = matrix.merge( group, on = [\"item_id\"], how = \"left\" )\n",
    "matrix[\"item_avg_item_price\"] = matrix.item_avg_item_price.astype(np.float16)\n",
    "\n",
    "\n",
    "group = train.groupby( [\"date_block_num\",\"item_id\"] ).agg( {\"item_price\": [\"mean\"]} )\n",
    "group.columns = [\"date_item_avg_item_price\"]\n",
    "group.reset_index(inplace = True)\n",
    "\n",
    "matrix = matrix.merge(group, on = [\"date_block_num\",\"item_id\"], how = \"left\")\n",
    "matrix[\"date_item_avg_item_price\"] = matrix.date_item_avg_item_price.astype(np.float16)\n",
    "lags = [1, 2, 3]\n",
    "matrix = lag_feature( matrix, lags, [\"date_item_avg_item_price\"] )\n",
    "for i in lags:\n",
    "    matrix[\"delta_price_lag_\" + str(i) ] = (matrix[\"date_item_avg_item_price_lag_\" + str(i)]- matrix[\"item_avg_item_price\"] )/ matrix[\"item_avg_item_price\"]\n",
    "\n",
    "def select_trends(row) :\n",
    "    for i in lags:\n",
    "        if row[\"delta_price_lag_\" + str(i)]:\n",
    "            return row[\"delta_price_lag_\" + str(i)]\n",
    "    return 0\n",
    "\n",
    "matrix[\"delta_price_lag\"] = matrix.apply(select_trends, axis = 1)\n",
    "matrix[\"delta_price_lag\"] = matrix.delta_price_lag.astype( np.float16 )\n",
    "matrix[\"delta_price_lag\"].fillna( 0 ,inplace = True)\n",
    "\n",
    "features_to_drop = [\"item_avg_item_price\", \"date_item_avg_item_price\"]\n",
    "for i in lags:\n",
    "    features_to_drop.append(\"date_item_avg_item_price_lag_\" + str(i) )\n",
    "    features_to_drop.append(\"delta_price_lag_\" + str(i) )\n",
    "matrix.drop(features_to_drop, axis = 1, inplace = True)\n",
    "time.time() - ts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Add total shop revenue per month to matix df. \n",
    "* Add lag values of revenue per month.\n",
    "* Add delta revenue values - how current month revenue relates to global average."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts = time.time()\n",
    "group = train.groupby( [\"date_block_num\",\"shop_id\"] ).agg({\"revenue\": [\"sum\"] })\n",
    "group.columns = [\"date_shop_revenue\"]\n",
    "group.reset_index(inplace = True)\n",
    "\n",
    "matrix = matrix.merge( group , on = [\"date_block_num\", \"shop_id\"], how = \"left\" )\n",
    "matrix['date_shop_revenue'] = matrix['date_shop_revenue'].astype(np.float32)\n",
    "\n",
    "group = group.groupby([\"shop_id\"]).agg({ \"date_block_num\":[\"mean\"] })\n",
    "group.columns = [\"shop_avg_revenue\"]\n",
    "group.reset_index(inplace = True )\n",
    "\n",
    "matrix = matrix.merge( group, on = [\"shop_id\"], how = \"left\" )\n",
    "matrix[\"shop_avg_revenue\"] = matrix.shop_avg_revenue.astype(np.float32)\n",
    "matrix[\"delta_revenue\"] = (matrix['date_shop_revenue'] - matrix['shop_avg_revenue']) / matrix['shop_avg_revenue']\n",
    "matrix[\"delta_revenue\"] = matrix[\"delta_revenue\"]. astype(np.float32)\n",
    "\n",
    "matrix = lag_feature(matrix, [1], [\"delta_revenue\"])\n",
    "matrix[\"delta_revenue_lag_1\"] = matrix[\"delta_revenue_lag_1\"].astype(np.float32)\n",
    "matrix.drop( [\"date_shop_revenue\", \"shop_avg_revenue\", \"delta_revenue\"] ,axis = 1, inplace = True)\n",
    "time.time() - ts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add month and number of days in each month to matrix df."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix[\"month\"] = matrix[\"date_block_num\"] % 12\n",
    "days = pd.Series([31,28,31,30,31,30,31,31,30,31,30,31])\n",
    "matrix[\"days\"] = matrix[\"month\"].map(days).astype(np.int8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add the month of each shop and item first sale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts = time.time()\n",
    "matrix[\"item_shop_first_sale\"] = matrix[\"date_block_num\"] - matrix.groupby([\"item_id\",\"shop_id\"])[\"date_block_num\"].transform('min')\n",
    "matrix[\"item_first_sale\"] = matrix[\"date_block_num\"] - matrix.groupby([\"item_id\"])[\"date_block_num\"].transform('min')\n",
    "time.time() - ts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Delete first three months from matrix. They don't have lag values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts = time.time()\n",
    "matrix = matrix[matrix[\"date_block_num\"] > 3]\n",
    "time.time() - ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix.head().T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import pickle\n",
    "from xgboost import XGBRegressor\n",
    "from matplotlib.pylab import rcParams\n",
    "rcParams['figure.figsize'] = 12, 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = matrix.copy()\n",
    "del matrix\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[data[\"date_block_num\"]==34].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use month 34 as validation for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = data[data.date_block_num < 33].drop(['item_cnt_month'], axis=1)\n",
    "Y_train = data[data.date_block_num < 33]['item_cnt_month']\n",
    "X_valid = data[data.date_block_num == 33].drop(['item_cnt_month'], axis=1)\n",
    "Y_valid = data[data.date_block_num == 33]['item_cnt_month']\n",
    "X_test = data[data.date_block_num == 34].drop(['item_cnt_month'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train = Y_train.clip(0, 20)\n",
    "Y_valid = Y_valid.clip(0, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del data\n",
    "gc.collect();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts = time.time()\n",
    "\n",
    "model = XGBRegressor(\n",
    "    max_depth=10,\n",
    "    n_estimators=1000,\n",
    "    min_child_weight=0.5, \n",
    "    colsample_bytree=0.8, \n",
    "    subsample=0.8, \n",
    "    eta=0.1,\n",
    "#     tree_method='gpu_hist',\n",
    "    seed=42)\n",
    "\n",
    "model.fit(\n",
    "    X_train, \n",
    "    Y_train, \n",
    "    eval_metric=\"rmse\", \n",
    "    eval_set=[(X_train, Y_train), (X_valid, Y_valid)], \n",
    "    verbose=True, \n",
    "    early_stopping_rounds = 20)\n",
    "\n",
    "time.time() - ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred = model.predict(X_valid).clip(0, 20)\n",
    "Y_test = model.predict(X_test).clip(0, 20)\n",
    "\n",
    "submission = pd.DataFrame({\n",
    "    \"ID\": test.index, \n",
    "    \"item_cnt_month\": Y_test\n",
    "})\n",
    "submission.to_csv('xgb_submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import plot_importance\n",
    "\n",
    "def plot_features(booster, figsize):    \n",
    "    fig, ax = plt.subplots(1,1,figsize=figsize)\n",
    "    return plot_importance(booster=booster, ax=ax)\n",
    "\n",
    "plot_features(model, (10,14))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
